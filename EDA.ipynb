{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3912bac2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  Exploratory Data Analysis (EDA) on Student Grades\n",
    "\n",
    "**Goal:** practice end‑to‑end EDA on a small, intentionally \"messy\" dataset (35 students).  \n",
    "You will:\n",
    "- Generate **synthetic data** (First Name, Last Name, Grade).  \n",
    "- **Inject data issues**: missing values, negative grades, out-of-range values (e.g., 540).  \n",
    "- Perform **EDA**: preview, schema, summary stats, missingness, range checks, outlier flags.  \n",
    "- **Fix errors** with documented, reproducible rules.  \n",
    "- **Visualize** the distribution **before & after** cleaning.  \n",
    "\n",
    "> Replace or extend any section with your own dataset later. Keep the *structure* and *explanations*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414bcc7",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Environment Setup\n",
    "\n",
    "We use standard libraries only:\n",
    "- `pandas` for data wrangling\n",
    "- `numpy` for random generation and numeric ops\n",
    "- `matplotlib` for basic plots\n",
    "\n",
    "> No external installs required. If you run into missing modules, install them in your environment (e.g., `pip install pandas numpy matplotlib`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bbec22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For reproducibility\n",
    "rng = np.random.default_rng(4064)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515087a",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Generate Synthetic Data (35 students)\n",
    "\n",
    "**Design:**\n",
    "- Randomly sample first and last names from small lists.\n",
    "- Generate grades around a typical distribution (mean≈75, std≈12).\n",
    "- Create a DataFrame with columns: `FirstName`, `LastName`, `Grade`.\n",
    "\n",
    "We'll **intentionally introduce errors** in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Small name banks (edit/expand as you like)\n",
    "first_names = [\n",
    "    \"Alex\",\"Taylor\",\"Jordan\",\"Riley\",\"Casey\",\"Avery\",\"Morgan\",\"Quinn\",\"Jamie\",\"Skyler\",\n",
    "    \"Sam\",\"Cameron\",\"Drew\",\"Jesse\",\"Parker\",\"Rowan\",\"Hayden\",\"Reese\",\"Emerson\",\"Logan\",\n",
    "    \"Milan\",\"Noa\",\"Eden\",\"Remy\",\"Ari\",\"Kendall\",\"Harley\",\"Corey\",\"Shay\",\"Sage\",\n",
    "    \"Blake\",\"Shawn\",\"Robin\",\"Kris\",\"Cody\"\n",
    "]\n",
    "\n",
    "last_names = [\n",
    "    \"Smith\",\"Lee\",\"Patel\",\"Brown\",\"Martin\",\"Garcia\",\"Nguyen\",\"Johnson\",\"Williams\",\"Davis\",\n",
    "    \"Miller\",\"Wilson\",\"Anderson\",\"Thomas\",\"Lopez\",\"Harris\",\"Clark\",\"Lewis\",\"Walker\",\"Young\",\n",
    "    \"King\",\"Wright\",\"Hill\",\"Scott\",\"Green\",\"Baker\",\"Adams\",\"Nelson\",\"Carter\",\"Mitchell\",\n",
    "    \"Perez\",\"Roberts\",\"Turner\",\"Phillips\",\"Campbell\"\n",
    "]\n",
    "\n",
    "# Generate base grades ~ N(75, 12), clipped to [0, 100] initially (we'll add errors later)\n",
    "base_grades = np.clip(rng.normal(loc=75, scale=12, size=35), 0, 100).round(1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"FirstName\": first_names,\n",
    "    \"LastName\": last_names,\n",
    "    \"Grade\": base_grades\n",
    "})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb29439",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Inject Data Issues (Missing, Negative, Out-of-Range)\n",
    "\n",
    "We simulate common data quality problems:\n",
    "- Missing values (`NaN`)\n",
    "- Negative grades (e.g., `-10`)\n",
    "- Out-of-range high values (e.g., `540` where `54` was intended)\n",
    "\n",
    "> **Why simulate problems?** EDA isn't just stats; it's about *diagnosing and repairing* real‑world messiness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dirty = df.copy()\n",
    "\n",
    "# Inject a few issues deterministically so everyone's notebook is similar\n",
    "issue_indices = rng.choice(df_dirty.index, size=6, replace=False)\n",
    "\n",
    "# 2 missing grades\n",
    "df_dirty.loc[issue_indices[0], \"Grade\"] = np.nan\n",
    "df_dirty.loc[issue_indices[1], \"Grade\"] = np.nan\n",
    "\n",
    "# 2 negative grades\n",
    "df_dirty.loc[issue_indices[2], \"Grade\"] = -10\n",
    "df_dirty.loc[issue_indices[3], \"Grade\"] = -3\n",
    "\n",
    "# 1 extreme high (likely 10x typo)\n",
    "df_dirty.loc[issue_indices[4], \"Grade\"] = 540\n",
    "\n",
    "# 1 slightly >100 (e.g., 104) to test upper-bound fix\n",
    "df_dirty.loc[issue_indices[5], \"Grade\"] = 104\n",
    "\n",
    "print(\"Indices with injected issues:\", issue_indices.tolist())\n",
    "df_dirty.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fb3f4",
   "metadata": {},
   "source": [
    "\n",
    "## 4) EDA: Quick Preview & Schema\n",
    "\n",
    "Look at a **sample**, the **schema**, and **summary statistics** to get a sense of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef871e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Head:\")\n",
    "display(df_dirty.head())\n",
    "\n",
    "print(\"\\nInfo:\")\n",
    "display(df_dirty.info())\n",
    "\n",
    "print(\"\\nDescribe (numeric):\")\n",
    "display(df_dirty.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50feac",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Missingness & Validity Checks\n",
    "\n",
    "**Checks:**\n",
    "- Missing values per column\n",
    "- Count invalid grades: `<0` or `>100`\n",
    "- Identify obvious 10× typos (e.g., values > 100 and ending with a '0')\n",
    "\n",
    "> These *rule‑based* checks should be **clear** and **defensible**. Document your assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_counts = df_dirty.isna().sum()\n",
    "\n",
    "invalid_negative = (df_dirty[\"Grade\"] < 0).sum(skipna=True)\n",
    "invalid_over_100 = (df_dirty[\"Grade\"] > 100).sum(skipna=True)\n",
    "\n",
    "# flag potential 10x typos: >100 and approximate multiple of 10 after rounding\n",
    "potential_ten_x = df_dirty[\"Grade\"].apply(lambda x: isinstance(x, (int, float)) and x>100 and abs(x/10 - round(x/10)) < 1e-9)\n",
    "\n",
    "summary_checks = pd.DataFrame({\n",
    "    \"missing\": missing_counts,\n",
    "})\n",
    "print(\"Missing values per column:\")\n",
    "display(summary_checks)\n",
    "\n",
    "print(f\"Invalid negatives: {invalid_negative}\")\n",
    "print(f\"Invalid >100: {invalid_over_100}\")\n",
    "print(\"Potential 10x-typos (value > 100 and ending in 0):\")\n",
    "display(df_dirty.loc[potential_ten_x.fillna(False), [\"FirstName\",\"LastName\",\"Grade\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe20c2",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Visualize Distribution (Before Cleaning)\n",
    "\n",
    "Plot the grade distribution to see the impact of errors and missing values.\n",
    "> Keep plots simple and readable. (One chart per cell; do not set custom colors.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69495658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "df_dirty[\"Grade\"].plot(kind=\"hist\", bins=15, edgecolor=\"black\")\n",
    "plt.title(\"Grade Distribution (Before Cleaning)\")\n",
    "plt.xlabel(\"Grade\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1783e6c",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Cleaning Strategy (Documented Rules)\n",
    "\n",
    "We will apply **clear, reproducible** rules:\n",
    "1. **Fix obvious 10× typos**: if `Grade > 100` *and* ends with `0`, divide by 10 (e.g., `540 → 54`).  \n",
    "2. **Clip out-of-range values**: after step 1, clip remaining grades to `[0, 100]`.  \n",
    "3. **Impute missing values**: use the **median** (robust to outliers) of valid grades.  \n",
    "4. Keep a **cleaning log** of what changed.\n",
    "\n",
    "> Replace these with your own rules when you switch to your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df_dirty.copy()\n",
    "\n",
    "cleaning_log = []\n",
    "\n",
    "# 1) Fix 10x typos\n",
    "ten_x_mask = df_clean[\"Grade\"].apply(lambda x: isinstance(x, (int, float)) and x>100 and abs(x/10 - round(x/10)) < 1e-9)\n",
    "df_clean.loc[ten_x_mask, \"Grade\"] = df_clean.loc[ten_x_mask, \"Grade\"] / 10.0\n",
    "cleaning_log.append(f\"Divided {ten_x_mask.sum()} suspected 10x-typo grade(s) by 10.\")\n",
    "\n",
    "# 2) Clip to [0, 100]\n",
    "before_clip_out_of_range = ((df_clean[\"Grade\"] < 0) | (df_clean[\"Grade\"] > 100)).sum(skipna=True)\n",
    "df_clean[\"Grade\"] = df_clean[\"Grade\"].clip(lower=0, upper=100)\n",
    "after_clip_out_of_range = ((df_clean[\"Grade\"] < 0) | (df_clean[\"Grade\"] > 100)).sum(skipna=True)\n",
    "cleaning_log.append(f\"Clipped out-of-range values: before={before_clip_out_of_range}, after={after_clip_out_of_range}.\")\n",
    "\n",
    "# 3) Impute missing with median of valid grades\n",
    "median_grade = df_clean[\"Grade\"].median(skipna=True)\n",
    "n_missing = df_clean[\"Grade\"].isna().sum()\n",
    "df_clean[\"Grade\"] = df_clean[\"Grade\"].fillna(median_grade)\n",
    "cleaning_log.append(f\"Imputed {n_missing} missing grade(s) with median={median_grade:.1f}.\")\n",
    "\n",
    "print(\"\\n\".join(cleaning_log))\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780f7fc",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Validate After Cleaning\n",
    "\n",
    "Double‑check:\n",
    "- No missing grades\n",
    "- All grades within `[0, 100]`\n",
    "- Summary stats look reasonable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e363a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Any missing now?\", df_clean[\"Grade\"].isna().any())\n",
    "print(\"Any out-of-range now?\", ((df_clean[\"Grade\"] < 0) | (df_clean[\"Grade\"] > 100)).any())\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53434d4",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Visualize Distribution (After Cleaning)\n",
    "\n",
    "Compare with the earlier plot. Is the distribution more plausible?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "df_clean[\"Grade\"].plot(kind=\"hist\", bins=15, edgecolor=\"black\")\n",
    "plt.title(\"Grade Distribution (After Cleaning)\")\n",
    "plt.xlabel(\"Grade\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47fdeeb",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Save Outputs\n",
    "\n",
    "Save both the **raw-with-issues** and **cleaned** datasets to `outputs/` for your portfolio repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c37f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "out_dir = Path(\"outputs\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "raw_path = out_dir / \"student_grades_raw.csv\"\n",
    "clean_path = out_dir / \"student_grades_clean.csv\"\n",
    "\n",
    "df_dirty.to_csv(raw_path, index=False)\n",
    "df_clean.to_csv(clean_path, index=False)\n",
    "\n",
    "print(f\"Saved raw → {raw_path}\")\n",
    "print(f\"Saved clean → {clean_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a399ae2",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Reflection (Short Answer)\n",
    "\n",
    "Add a few bullets here summarizing what you learned:\n",
    "- Which checks caught the most issues?\n",
    "- Which assumptions did you make? Are they defensible?\n",
    "- If this were a production pipeline, how would you log anomalies and fixes?\n",
    "- What would you change if you had categorical grades (A/B/C) instead of numeric?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
